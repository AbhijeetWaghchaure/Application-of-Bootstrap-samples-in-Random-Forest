{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Application of Bootstrap samples in Random Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ag91ijrQOs"
      },
      "source": [
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHOsONTt1K_"
      },
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc1htEFYuLRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e68463b-e941-4625-be05-e08760d10f9b"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQle3T_wuOa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8ee664-1f3a-4478-a9e8-395697b76115"
      },
      "source": [
        "x[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
              "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
              "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
              "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
              "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx0tp1fqRW35",
        "outputId": "923ef4f9-ab96-4975-82de-deb71497c546"
      },
      "source": [
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6gxZEsFWm-8"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fHTdS_zpgG"
      },
      "source": [
        "# <font color='blue'> <b>Task - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yGBuryOwHz"
      },
      "source": [
        "<font color='blue'><b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXX8vf3z073"
      },
      "source": [
        "*  <font color='blue'> <b>Creating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVaWG1F4uCZ"
      },
      "source": [
        "<font color='Orange'><b>Algorithm</b></font>\n",
        "\n",
        "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_oWoN97BhDY"
      },
      "source": [
        "*  <font color='blue'><b> Write code for generating samples</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph_6D2SDzz7F"
      },
      "source": [
        "    '''In this function, we will write code for generating 30 samples '''\n",
        "    # you can use random.choice to generate random indices without replacement\n",
        "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
        "    # Please follow above pseudo code for generating samples\n",
        "    # note please return as lists\n",
        "\n",
        "def generating_samples(input_data, target_data):\n",
        "  selecting_rows = np.random.choice(len(input_data), 303, replace=False) #selection of 303 random rows\n",
        "  replacing_rows = np.random.choice(selecting_rows, 203, replace=False) #extracting 206 random rows indices from the selecting rows\n",
        "  selecting_columns = random.randint(3, 13) # selecting columns\n",
        "  columns_selected = np.array(random.sample(range(0, 13), selecting_columns)) #select random columns from 3 to 13\n",
        "  sample_data = input_data[selecting_rows[:, None], columns_selected]\n",
        "  target_of_sample_data = target_data[selecting_rows]\n",
        "  \n",
        "  #Replicating data\n",
        "  replicate_sample_data = input_data[replacing_rows[:, None], columns_selected ]\n",
        "  target_of_replicate_sample_data = target_data[replacing_rows]  \n",
        "\n",
        "  #Concatinating data\n",
        "  final_sample_data =  np.vstack((sample_data, replicate_sample_data))\n",
        "  final_target_data =  np.vstack((target_of_sample_data.reshape(-1, 1), target_of_replicate_sample_data.reshape(-1, 1) ))\n",
        "\n",
        "  return final_sample_data, final_target_data, selecting_rows, columns_selected\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvuhNzm7uld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4decef9e-86db-4d12-b4bb-14db35025e38"
      },
      "source": [
        "def grader_samples(a,b,c,d):\n",
        "    length = (len(a)==506  and len(b)==506)\n",
        "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
        "    rows_length = (len(c)==303)\n",
        "    column_length= (len(d)>=3)\n",
        "    assert(length and sampled and rows_length and column_length)\n",
        "    return True\n",
        "a,b,c,d = generating_samples(x, y)\n",
        "grader_samples(a,b,c,d)\n",
        "print(\"Final sample data\")\n",
        "print(a.shape)\n",
        "print(\"-\"*50)\n",
        "print(\"Final Target Data\")\n",
        "print(b.shape)\n",
        "print(\"-\"*50)\n",
        "print(\"Rows Selected\")\n",
        "print(c.shape)\n",
        "print(\"-\"*50)\n",
        "print(\"Columns Selected\")\n",
        "print(d.shape)\n",
        "print(\"-\"*50)\n",
        "grader_samples(a,b,c,d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final sample data\n",
            "(506, 3)\n",
            "--------------------------------------------------\n",
            "Final Target Data\n",
            "(506, 1)\n",
            "--------------------------------------------------\n",
            "Rows Selected\n",
            "(303,)\n",
            "--------------------------------------------------\n",
            "Columns Selected\n",
            "(3,)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4LSsmn4Jn2_"
      },
      "source": [
        "*  <font color='blue'> <b>Create 30 samples </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7MN6sL2BZ"
      },
      "source": [
        "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXlKWjCcBvTk"
      },
      "source": [
        "# Use generating_samples function to create 30 samples \n",
        "# store these created samples in a list\n",
        "list_input_data =[]\n",
        "list_output_data =[]\n",
        "list_selected_row= []\n",
        "list_selected_columns=[]\n",
        "\n",
        "for i in range(0,30):\n",
        "  a,b,c,d = generating_samples(x,y)\n",
        "  list_input_data.append(a)\n",
        "  list_output_data.append(b)\n",
        "  list_selected_row.append(c)\n",
        "  list_selected_columns.append(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUz9VFiMQkh"
      },
      "source": [
        "<font color='cyan'> <b>Grader function - 2 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCvIq8NuMWOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64edb08-fe4e-4e06-eca1-9e644c7cb7d7"
      },
      "source": [
        "def grader_30(a):\n",
        "    assert(len(a)==30 and len(a[0])==506)\n",
        "    return True\n",
        "grader_30(list_input_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv-mkZkO6dh"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaHCPB0O8qF"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy4zXSWPtU8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for building tree</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvH06HPQBdP"
      },
      "source": [
        "![alt text](https://i.imgur.com/pcXfSmp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwPO_uHQjul"
      },
      "source": [
        "*  <font color='blue'><b> Write code for building regression trees</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQp6tRwMthq"
      },
      "source": [
        "list_of_all_models_decision_tree = []\n",
        "for i in range(0, 30):\n",
        "  model_i = DecisionTreeRegressor(max_depth=None)\n",
        "  model_i.fit(list_input_data[i], list_output_data[i])\n",
        "  list_of_all_models_decision_tree.append(model_i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j8BKfAQ1U8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0mTBD2RBx_"
      },
      "source": [
        "![alt text](https://i.imgur.com/sPEE618.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-UamlHRjPy"
      },
      "source": [
        "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIMT7_oR312"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWhcvMRWRA9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cec0d58-9245-4d61-8504-73775e6d0e11"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import median\n",
        "from statistics import mean\n",
        "\n",
        "array_of_y =[]\n",
        "\n",
        "for i in range (0,30):\n",
        "  data_point_i = x[:, list_selected_columns[i]]\n",
        "  target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
        "  array_of_y.append(target_y_i)\n",
        "\n",
        "predicted_array_of_target_y = np.array(array_of_y)\n",
        "predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
        "\n",
        "print(\"Predicted values using Decision Tree:\")\n",
        "print(predicted_array_of_target_y[:5,])\n",
        "print(\"-\"*50)\n",
        "print(\"Dimensions of Predicted Array of Target y : \", predicted_array_of_target_y.shape) #print(predicted_array_of_target_y.shape)\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Now to calculate MSE, first calculate the Median of Predicted Y\n",
        "# passing axis=1 will make sure the medians are computed along axis=1\n",
        "\n",
        "# Now to calculate MSE, first calculate the Median of Predicted Y\n",
        "# passing axis=1 will make sure the medians are computed along axis=1\n",
        "\n",
        "median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
        "median_predicted_y.shape\n",
        "print(\"MSE (Using Median): \", mean_squared_error(y, median_predicted_y ))\n",
        "\n",
        "print(\"-\"*50)\n",
        "\n",
        "mean_predicted_y = np.mean(predicted_array_of_target_y, axis=1)\n",
        "mean_predicted_y.shape\n",
        "print(\"MSE (Using Mean): \", mean_squared_error(y, mean_predicted_y ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values using Decision Tree:\n",
            "[[24.         32.2        18.9        23.1        22.         32.7\n",
            "  24.         19.6        24.         32.         24.         23.8\n",
            "  24.         27.9        24.         28.         35.1        24.\n",
            "  24.         37.2        24.         24.         24.         35.1\n",
            "  24.         23.6        24.         31.6        23.8        24.        ]\n",
            " [21.6        21.6        21.6        21.7        21.6        20.47142857\n",
            "  21.6        34.7        21.6        21.6        21.6        21.6\n",
            "  23.6        22.         22.9        21.6        24.6        20.7\n",
            "  21.6        21.6        21.6        21.2        24.4        11.9\n",
            "  21.6        21.6        21.6        21.6        21.6        24.4       ]\n",
            " [21.6        21.6        34.7        34.7        22.5        20.47142857\n",
            "  34.7        34.7        34.7        34.7        36.1        35.4\n",
            "  33.         34.7        37.9        34.7        34.7        33.3\n",
            "  34.7        34.7        44.8        34.7        33.4        34.7\n",
            "  34.7        33.1        34.7        34.7        34.7        34.7       ]\n",
            " [33.4        33.4        28.7        33.4        33.4        32.76666667\n",
            "  33.4        35.2        33.4        33.4        29.6        33.4\n",
            "  33.         33.4        26.6        33.4        35.4        33.4\n",
            "  50.         33.4        33.1        50.         33.4        33.4\n",
            "  33.4        33.4        33.4        33.4        33.4        33.4       ]\n",
            " [36.2        36.2        28.7        36.2        33.4        32.76666667\n",
            "  36.2        35.2        36.2        33.         36.2        37.9\n",
            "  28.5        33.         36.2        33.4        33.         36.2\n",
            "  36.2        26.6        36.2        36.2        36.2        34.7\n",
            "  36.2        36.2        33.4        32.7        36.2        36.2       ]]\n",
            "--------------------------------------------------\n",
            "Dimensions of Predicted Array of Target y :  (506, 30)\n",
            "--------------------------------------------------\n",
            "MSE (Using Median):  0.09576127288860214\n",
            "--------------------------------------------------\n",
            "MSE (Using Mean):  2.68640227672939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuclPDMnSz8F"
      },
      "source": [
        "<font color='blue'><b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb9FSIDTM5V"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB-d6NMETbd9"
      },
      "source": [
        "![alt text](https://i.imgur.com/95S5Mtm.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW3GOcFzTqbt"
      },
      "source": [
        "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqcS03pUYSZ"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fog_6DNdS-h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a657645-2f49-4370-ed89-2626d1cfe8bc"
      },
      "source": [
        "y_predicted_oob_median_list = []\n",
        "\n",
        "for i in range(0, 506):\n",
        "  indices_for_oob_models = []\n",
        "\n",
        "  # For each of i-th row I have to build a list, of sample size 30\n",
        "  # ONLY condition is i-th row should not be part of the list_selected_row[i-th]\n",
        "  # e.g. say for i = 469 and index_oob in below loop is 10 then \n",
        "  # list_selected_row[10] (which is an array of row-numbers) should not contain the 469-th row\n",
        "\n",
        "  for index_oob in range(0, 30):\n",
        "    if i not in list_selected_row[index_oob]:\n",
        "      indices_for_oob_models.append(index_oob)\n",
        "\n",
        "  \n",
        "  y_predicted_oob_list = []\n",
        "\n",
        "  for oob_model_index in indices_for_oob_models:\n",
        "    model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
        "\n",
        "    row_oob = x[i]\n",
        "\n",
        "    #Now extract ONLY those specific columns/featues that were selected during the bootstrapping\n",
        "\n",
        "    x_oob_data_point = [row_oob[columns] for columns in list_selected_columns[oob_model_index]]\n",
        "\n",
        "    x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1) #print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
        "\n",
        "    y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
        "    y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
        "   \n",
        "  y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
        "  y_predicted_median = np.median(y_predicted_oob_list)\n",
        "  y_predicted_oob_median_list.append(y_predicted_median)\n",
        "\n",
        "def calculate_oob_score(num_rows):\n",
        "  oob_score = 0\n",
        "  for i in range(0, num_rows):\n",
        "    oob_score += ((y[i] - y_predicted_oob_median_list[i]) ** 2)\n",
        "  final_oob_score = oob_score/506\n",
        "  return final_oob_score\n",
        "\n",
        "print(\"Final OOB Score is \", calculate_oob_score(506))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final OOB Score is  15.350442599179564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiwX3OUjUI"
      },
      "source": [
        "# <font color='blue'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceW5-D88Uswi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa6c9c2-a5f4-406b-92df-36e086f7063f"
      },
      "source": [
        "# Function to build the entire bootstrapping steps that we did above and\n",
        "# Reurning from the function the MSE and oob score\n",
        "def bootstrapping_and_oob(x, y):\n",
        "\n",
        "  # Use generating_samples function to create 30 samples \n",
        "  # store these created samples in a list\n",
        "  list_input_data =[]\n",
        "  list_output_data =[]\n",
        "  list_selected_row= []\n",
        "  list_selected_columns=[]\n",
        "  \n",
        "  for i in range (0, 30):\n",
        "    a, b, c, d = generating_samples(x, y)\n",
        "    list_input_data.append(a)\n",
        "    list_output_data.append(b)\n",
        "    list_selected_row.append(c)\n",
        "    list_selected_columns.append(d)\n",
        "\n",
        "   #Building Regression Trees:\n",
        "  list_of_all_models_decision_tree = []\n",
        "  for i in range(0, 30):\n",
        "    model_i = DecisionTreeRegressor(max_depth=None)\n",
        "    model_i.fit(list_input_data[i], list_output_data[i])\n",
        "    list_of_all_models_decision_tree.append(model_i)\n",
        "  \n",
        "   # calculating MSE\n",
        "  array_of_Y = []\n",
        "\n",
        "  for i in range(0, 30):\n",
        "    data_point_i = x[:, list_selected_columns[i]]\n",
        "    target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
        "    array_of_Y.append(target_y_i)\n",
        "    \n",
        "    \n",
        "  predicted_array_of_target_y = np.array(array_of_Y)\n",
        "  predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
        "\n",
        "    # print(predicted_array_of_target_y.shape)\n",
        "    # Now to calculate MSE, first calculate the Median of Predicted Y\n",
        "    # passing axis=1 will make sure the medians are computed along axis=1\n",
        "\n",
        "  median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
        "\n",
        "  MSE = mean_squared_error(y, median_predicted_y ) #Final MSE\n",
        "\n",
        "    # Calculating OOB Score\n",
        "  y_predicted_oob_median_list = []\n",
        "  for i in range(0, 506):\n",
        "    indices_for_oob_models = []\n",
        "\n",
        "    # For each of i-th row I shall build a list of sample size 30\n",
        "    # ONLY condition being that this ith row should not be part of\n",
        "    # the list_selected_row\n",
        "\n",
        "\n",
        "    for index_oob in range(0, 30):\n",
        "      if i not in list_selected_row[index_oob]:\n",
        "        indices_for_oob_models.append(index_oob)\n",
        "\n",
        "    y_predicted_oob_list = []\n",
        "    for oob_model_index in indices_for_oob_models:\n",
        "      model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
        "      row_oob = x[i]\n",
        "        # print('oob_model_index ', oob_model_index)\n",
        "      x_oob_data_point = [row_oob[col] for col in list_selected_columns[oob_model_index] ]\n",
        "        # print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
        "      x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
        "\n",
        "      y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
        "      y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
        "\n",
        "    y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
        "    y_predicted_median = np.median(y_predicted_oob_list)\n",
        "    y_predicted_oob_median_list.append(y_predicted_median)\n",
        "\n",
        "    \n",
        "  oob_score = 0\n",
        "\n",
        "  for i in range(0, 506):\n",
        "    oob_score += (y[i] - y_predicted_oob_median_list[i] ) ** 2  # oob_score = (oob_score + (y[i] - y_predicted_oob_median_list[i] ) ** 2)\n",
        "                                          \n",
        "  final_oob_score = oob_score/506\n",
        "  return MSE, final_oob_score\n",
        "\n",
        "print(bootstrapping_and_oob(x, y))                                 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.063801004697107, 15.731620219554825)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coRQbQdxrTZ3",
        "outputId": "6898c552-c07f-4110-edf2-66fb1dcbf14e"
      },
      "source": [
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable\n",
        "\n",
        "mse_boston_35_times_arr = []\n",
        "oob_score_boston_35_times_arr = []\n",
        "\n",
        "# Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score\n",
        "for i in range(0, 35):\n",
        "  mse, oob_score = bootstrapping_and_oob(x, y)\n",
        "  mse_boston_35_times_arr.append(mse)\n",
        "  oob_score_boston_35_times_arr.append(oob_score)\n",
        "\n",
        "\n",
        "mse_boston_35_times_arr = np.array(mse_boston_35_times_arr)\n",
        "oob_score_boston_35_times_arr = np.array(oob_score_boston_35_times_arr)\n",
        "\n",
        "confidence_level = 0.95\n",
        "degrees_of_freedom = 34 # sample.size - 1\n",
        "\n",
        "mean_of_sample_mse_35 = np.mean(mse_boston_35_times_arr)\n",
        "standard_error_of_sample_mse_35 = scipy.stats.sem(mse_boston_35_times_arr)\n",
        "\n",
        "# confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
        "confidence_interval_mse_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_mse_35, standard_error_of_sample_mse_35 )\n",
        "print(\"Confidence Interval of MSE 35 Times \", confidence_interval_mse_35)\n",
        "\n",
        "# Now calculate confidence inter for oob score\n",
        "mean_of_sample_oob_score_35 = np.mean(oob_score_boston_35_times_arr)\n",
        "standard_error_of_sample_oob_score_35 = scipy.stats.sem(oob_score_boston_35_times_arr)\n",
        "\n",
        "confidence_interval_oob_score_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_oob_score_35, standard_error_of_sample_oob_score_35 )\n",
        "print(\"Confidence Interval of OOB Score 35 Times \", confidence_interval_oob_score_35)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence Interval of MSE 35 Times  (0.06969089322660793, 0.1382185426569405)\n",
            "Confidence Interval of OOB Score 35 Times  (13.441286506283376, 14.703192818207302)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sn9m5-zslPt"
      },
      "source": [
        "\n",
        "*   MSE - There is a 95% chance that the confidence interval of (0.06969089322660793, 0.1382185426569405) contains the true population mean of MSE.\n",
        "\n",
        "*   OOB Score - There is a 95% chance that the confidence interval of (13.441286506283376, 14.703192818207302) contains the true population mean of OOB Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTnJdiBVS_e"
      },
      "source": [
        "# <font color='blue'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxrvZqHV1Fr"
      },
      "source": [
        "<font color='orange'><b>Flowchart for Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjwEJ62V6a6"
      },
      "source": [
        "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emSwLL7VurD"
      },
      "source": [
        "![alt text](https://i.imgur.com/Y5cNhQk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29hjwKlWWDfo"
      },
      "source": [
        "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_pUlSD-VYD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa35e00b-90bf-4a9f-f68f-86e2bae1c226"
      },
      "source": [
        "def predict_y_given_x_bootstrap(x_query):\n",
        "  y_predicted_array_30_sample = []\n",
        "  \n",
        "  for i in range(0, 30):\n",
        "    model_i = list_of_all_models_decision_tree[i]\n",
        "    \n",
        "    # Extract x for ith data point with specific number of featues from list_selected_columns\n",
        "\n",
        "    x_data_point_i = [x_query[column] for column in list_selected_columns[i]]\n",
        "    x_data_point_i = np.array(x_data_point_i).reshape(1, -1)\n",
        "    y_predicted_i = model_i.predict(x_data_point_i)\n",
        "    y_predicted_array_30_sample.append(y_predicted_i)\n",
        "    \n",
        "  y_predicted_array_30_sample = np.array(y_predicted_array_30_sample)\n",
        "  y_predicted_median = np.median(y_predicted_array_30_sample)\n",
        "  return y_predicted_median\n",
        "\n",
        "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "y_predicted_for_xq = predict_y_given_x_bootstrap(xq)\n",
        "y_predicted_for_xq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.7"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdUi-0xWOJ9"
      },
      "source": [
        "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8luGjS7tmAE"
      },
      "source": [
        "**Observation for Task 1:**\n",
        "\n",
        "*   Successfuly create Random 30 samples from the whole boston data points using functions like generating_samples(x, y) & grader_30(a)\n",
        "*   Successfully built decision tree regressor on each sample\n",
        "*   After getting predicted_y for each data point, we useD sklearns mean_squared_error to calculate the MSE & OOB Score between predicted_y and actual_y.\n",
        "\n",
        "\n",
        "**Observation for Task 2:**\n",
        "\n",
        "*   Identified Confidence Interval for OOB Score as well as for MSE.\n",
        "*   MSE - There is a 95% chance that the confidence interval of (0.06969089322660793, 0.1382185426569405) contains the true population mean of MSE.\n",
        "*   OOB Score - There is a 95% chance that the confidence interval of (13.441286506283376, 14.703192818207302) contains the true population mean of OOB Score.\n",
        "\n",
        "\n",
        "**Observation for Task 3:**\n",
        "\n",
        "*   Given query point \"xq\" to 30 models and performed the regression on the output generated by 30 models\n",
        "*   Since we choose to take median on predict_y_given_x_bootstrap, the output generated by 30 models is 18.7"
      ]
    }
  ]
}